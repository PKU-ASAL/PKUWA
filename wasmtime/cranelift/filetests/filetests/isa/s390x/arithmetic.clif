test compile precise-output
target s390x

function %iadd_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = iadd.i128 v0, v1
  return v2
}

; block0:
;   vl %v0, 0(%r3)
;   vl %v1, 0(%r4)
;   vaq %v7, %v0, %v1
;   vst %v7, 0(%r2)
;   br %r14

function %iadd_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = iadd.i64 v0, v1
  return v2
}

; block0:
;   agr %r2, %r3
;   br %r14

function %iadd_i64_ext32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   agfr %r2, %r3
;   br %r14

function %iadd_i64_imm16(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 1
  v2 = iadd.i64 v0, v1
  return v2
}

; block0:
;   aghi %r2, 1
;   br %r14

function %iadd_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32768
  v2 = iadd.i64 v0, v1
  return v2
}

; block0:
;   agfi %r2, 32768
;   br %r14

function %iadd_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   ag %r2, 0(%r3)
;   br %r14

function %iadd_i64_mem_ext16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   agh %r2, 0(%r3)
;   br %r14

function %iadd_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = iadd.i64 v0, v2
  return v3
}

; block0:
;   agf %r2, 0(%r3)
;   br %r14

function %iadd_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = iadd.i32 v0, v1
  return v2
}

; block0:
;   ar %r2, %r3
;   br %r14

function %iadd_i32_imm16(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 1
  v2 = iadd.i32 v0, v1
  return v2
}

; block0:
;   ahi %r2, 1
;   br %r14

function %iadd_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32768
  v2 = iadd.i32 v0, v1
  return v2
}

; block0:
;   afi %r2, 32768
;   br %r14

function %iadd_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   a %r2, 0(%r3)
;   br %r14

function %iadd_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   ay %r2, 4096(%r3)
;   br %r14

function %iadd_i32_mem_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   ah %r2, 0(%r3)
;   br %r14

function %iadd_i32_memoff_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = iadd.i32 v0, v2
  return v3
}

; block0:
;   ahy %r2, 4096(%r3)
;   br %r14

function %iadd_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = iadd.i16 v0, v1
  return v2
}

; block0:
;   ar %r2, %r3
;   br %r14

function %iadd_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 1
  v2 = iadd.i16 v0, v1
  return v2
}

; block0:
;   ahi %r2, 1
;   br %r14

function %iadd_i16_mem(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = iadd.i16 v0, v2
  return v3
}

; block0:
;   ah %r2, 0(%r3)
;   br %r14

function %iadd_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = iadd.i8 v0, v1
  return v2
}

; block0:
;   ar %r2, %r3
;   br %r14

function %iadd_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 1
  v2 = iadd.i8 v0, v1
  return v2
}

; block0:
;   ahi %r2, 1
;   br %r14

function %iadd_i8_mem(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = iadd.i8 v0, v2
  return v3
}

; block0:
;   llc %r3, 0(%r3)
;   ar %r2, %r3
;   br %r14

function %iadd_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2, v3 = iadd_ifcout.i64 v0, v1
  return v2
}

; block0:
;   algr %r2, %r3
;   br %r14

function %iadd_i64_ext32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
  v2 = uextend.i64 v1
  v3, v4 = iadd_ifcout.i64 v0, v2
  return v3
}

; block0:
;   algfr %r2, %r3
;   br %r14

function %iadd_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32768
  v2, v3 = iadd_ifcout.i64 v0, v1
  return v2
}

; block0:
;   algfi %r2, 32768
;   br %r14

function %iadd_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3, v4 = iadd_ifcout.i64 v0, v2
  return v3
}

; block0:
;   lg %r3, 0(%r3)
;   algr %r2, %r3
;   br %r14

function %iadd_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = uload32.i64 v1
  v3, v4 = iadd_ifcout.i64 v0, v2
  return v3
}

; block0:
;   llgf %r3, 0(%r3)
;   algr %r2, %r3
;   br %r14

function %iadd_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2, v3 = iadd_ifcout.i32 v0, v1
  return v2
}

; block0:
;   alr %r2, %r3
;   br %r14

function %iadd_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32768
  v2, v3 = iadd_ifcout.i32 v0, v1
  return v2
}

; block0:
;   alfi %r2, 32768
;   br %r14

function %iadd_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3, v4 = iadd_ifcout.i32 v0, v2
  return v3
}

; block0:
;   l %r3, 0(%r3)
;   alr %r2, %r3
;   br %r14

function %iadd_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3, v4 = iadd_ifcout.i32 v0, v2
  return v3
}

; block0:
;   ly %r3, 4096(%r3)
;   alr %r2, %r3
;   br %r14

function %isub_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = isub.i128 v0, v1
  return v2
}

; block0:
;   vl %v0, 0(%r3)
;   vl %v1, 0(%r4)
;   vsq %v7, %v0, %v1
;   vst %v7, 0(%r2)
;   br %r14

function %isub_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = isub.i64 v0, v1
  return v2
}

; block0:
;   sgr %r2, %r3
;   br %r14

function %isub_i64_ext32(i64, i32) -> i64 {
block0(v0: i64, v1: i32):
  v2 = sextend.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sgfr %r2, %r3
;   br %r14

function %isub_i64_imm16(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 1
  v2 = isub.i64 v0, v1
  return v2
}

; block0:
;   aghi %r2, -1
;   br %r14

function %isub_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32769
  v2 = isub.i64 v0, v1
  return v2
}

; block0:
;   agfi %r2, -32769
;   br %r14

function %isub_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sg %r2, 0(%r3)
;   br %r14

function %isub_i64_mem_ext16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sgh %r2, 0(%r3)
;   br %r14

function %isub_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = isub.i64 v0, v2
  return v3
}

; block0:
;   sgf %r2, 0(%r3)
;   br %r14

function %isub_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = isub.i32 v0, v1
  return v2
}

; block0:
;   sr %r2, %r3
;   br %r14

function %isub_i32_imm16(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 1
  v2 = isub.i32 v0, v1
  return v2
}

; block0:
;   ahi %r2, -1
;   br %r14

function %isub_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32769
  v2 = isub.i32 v0, v1
  return v2
}

; block0:
;   afi %r2, -32769
;   br %r14

function %isub_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   s %r2, 0(%r3)
;   br %r14

function %isub_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   sy %r2, 4096(%r3)
;   br %r14

function %isub_i32_mem_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   sh %r2, 0(%r3)
;   br %r14

function %isub_i32_memoff_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = isub.i32 v0, v2
  return v3
}

; block0:
;   shy %r2, 4096(%r3)
;   br %r14

function %isub_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = isub.i16 v0, v1
  return v2
}

; block0:
;   sr %r2, %r3
;   br %r14

function %isub_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 1
  v2 = isub.i16 v0, v1
  return v2
}

; block0:
;   ahi %r2, -1
;   br %r14

function %isub_i16_mem(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = isub.i16 v0, v2
  return v3
}

; block0:
;   sh %r2, 0(%r3)
;   br %r14

function %isub_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = isub.i8 v0, v1
  return v2
}

; block0:
;   sr %r2, %r3
;   br %r14

function %isub_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 1
  v2 = isub.i8 v0, v1
  return v2
}

; block0:
;   ahi %r2, -1
;   br %r14

function %isub_i8_mem(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = isub.i8 v0, v2
  return v3
}

; block0:
;   llc %r3, 0(%r3)
;   sr %r2, %r3
;   br %r14

function %iabs_i128(i128) -> i128 {
block0(v0: i128):
  v1 = iabs.i128 v0
  return v1
}

; block0:
;   vl %v0, 0(%r3)
;   vgbm %v5, 0
;   vsq %v7, %v5, %v0
;   vrepg %v17, %v0, 0
;   vchg %v19, %v5, %v17
;   vsel %v21, %v7, %v0, %v19
;   vst %v21, 0(%r2)
;   br %r14

function %iabs_i64(i64) -> i64 {
block0(v0: i64):
  v1 = iabs.i64 v0
  return v1
}

; block0:
;   lpgr %r2, %r2
;   br %r14

function %iabs_i64_ext32(i32) -> i64 {
block0(v0: i32):
  v1 = sextend.i64 v0
  v2 = iabs.i64 v1
  return v2
}

; block0:
;   lpgfr %r2, %r2
;   br %r14

function %iabs_i32(i32) -> i32 {
block0(v0: i32):
  v1 = iabs.i32 v0
  return v1
}

; block0:
;   lpr %r2, %r2
;   br %r14

function %iabs_i16(i16) -> i16 {
block0(v0: i16):
  v1 = iabs.i16 v0
  return v1
}

; block0:
;   lhr %r5, %r2
;   lpr %r2, %r5
;   br %r14

function %iabs_i8(i8) -> i8 {
block0(v0: i8):
  v1 = iabs.i8 v0
  return v1
}

; block0:
;   lbr %r5, %r2
;   lpr %r2, %r5
;   br %r14

function %ineg_i128(i128) -> i128 {
block0(v0: i128):
  v1 = ineg.i128 v0
  return v1
}

; block0:
;   vl %v0, 0(%r3)
;   vgbm %v5, 0
;   vsq %v7, %v5, %v0
;   vst %v7, 0(%r2)
;   br %r14

function %ineg_i64(i64) -> i64 {
block0(v0: i64):
  v1 = ineg.i64 v0
  return v1
}

; block0:
;   lcgr %r2, %r2
;   br %r14

function %ineg_i64_ext32(i32) -> i64 {
block0(v0: i32):
  v1 = sextend.i64 v0
  v2 = ineg.i64 v1
  return v2
}

; block0:
;   lcgfr %r2, %r2
;   br %r14

function %ineg_i32(i32) -> i32 {
block0(v0: i32):
  v1 = ineg.i32 v0
  return v1
}

; block0:
;   lcr %r2, %r2
;   br %r14

function %ineg_i16(i16) -> i16 {
block0(v0: i16):
  v1 = ineg.i16 v0
  return v1
}

; block0:
;   lcr %r2, %r2
;   br %r14

function %ineg_i8(i8) -> i8 {
block0(v0: i8):
  v1 = ineg.i8 v0
  return v1
}

; block0:
;   lcr %r2, %r2
;   br %r14

function %imul_i128(i128, i128) -> i128 {
block0(v0: i128, v1: i128):
  v2 = imul.i128 v0, v1
  return v2
}

;   stmg %r13, %r15, 104(%r15)
; block0:
;   vl %v0, 0(%r3)
;   vl %v1, 0(%r4)
;   lgdr %r5, %f0
;   vlgvg %r3, %v0, 1
;   lgdr %r4, %f1
;   vlgvg %r1, %v1, 1
;   lgr %r13, %r1
;   mlgr %r0, %r3
;   msgr %r3, %r4
;   lgr %r4, %r13
;   msgr %r5, %r4
;   agr %r3, %r0
;   agr %r5, %r3
;   vlvgp %v5, %r5, %r1
;   vst %v5, 0(%r2)
;   lmg %r13, %r15, 104(%r15)
;   br %r14

function %imul_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = imul.i64 v0, v1
  return v2
}

; block0:
;   msgr %r2, %r3
;   br %r14

function %imul_i64_imm16(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 3
  v2 = imul.i64 v0, v1
  return v2
}

; block0:
;   mghi %r2, 3
;   br %r14

function %imul_i64_imm32(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 32769
  v2 = imul.i64 v0, v1
  return v2
}

; block0:
;   msgfi %r2, 32769
;   br %r14

function %imul_i64_mem(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = load.i64 v1
  v3 = imul.i64 v0, v2
  return v3
}

; block0:
;   msg %r2, 0(%r3)
;   br %r14

function %imul_i64_mem_ext16(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload16.i64 v1
  v3 = imul.i64 v0, v2
  return v3
}

; block0:
;   mgh %r2, 0(%r3)
;   br %r14

function %imul_i64_mem_ext32(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sload32.i64 v1
  v3 = imul.i64 v0, v2
  return v3
}

; block0:
;   msgf %r2, 0(%r3)
;   br %r14

function %imul_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = imul.i32 v0, v1
  return v2
}

; block0:
;   msr %r2, %r3
;   br %r14

function %imul_i32_imm16(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 3
  v2 = imul.i32 v0, v1
  return v2
}

; block0:
;   mhi %r2, 3
;   br %r14

function %imul_i32_imm32(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 32769
  v2 = imul.i32 v0, v1
  return v2
}

; block0:
;   msfi %r2, 32769
;   br %r14

function %imul_i32_mem(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   ms %r2, 0(%r3)
;   br %r14

function %imul_i32_memoff(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = load.i32 v1+4096
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   msy %r2, 4096(%r3)
;   br %r14

function %imul_i32_mem_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   mh %r2, 0(%r3)
;   br %r14

function %imul_i32_memoff_ext16(i32, i64) -> i32 {
block0(v0: i32, v1: i64):
  v2 = sload16.i32 v1+4096
  v3 = imul.i32 v0, v2
  return v3
}

; block0:
;   mhy %r2, 4096(%r3)
;   br %r14

function %imul_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = imul.i16 v0, v1
  return v2
}

; block0:
;   msr %r2, %r3
;   br %r14

function %imul_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 3
  v2 = imul.i16 v0, v1
  return v2
}

; block0:
;   mhi %r2, 3
;   br %r14

function %imul_i16_mem(i16, i64) -> i16 {
block0(v0: i16, v1: i64):
  v2 = load.i16 v1
  v3 = imul.i16 v0, v2
  return v3
}

; block0:
;   mh %r2, 0(%r3)
;   br %r14

function %imul_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = imul.i8 v0, v1
  return v2
}

; block0:
;   msr %r2, %r3
;   br %r14

function %imul_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 3
  v2 = imul.i8 v0, v1
  return v2
}

; block0:
;   mhi %r2, 3
;   br %r14

function %imul_i8_mem(i8, i64) -> i8 {
block0(v0: i8, v1: i64):
  v2 = load.i8 v1
  v3 = imul.i8 v0, v2
  return v3
}

; block0:
;   llc %r3, 0(%r3)
;   msr %r2, %r3
;   br %r14

function %umulhi_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = umulhi.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r3
;   mlgr %r0, %r2
;   lgr %r2, %r0
;   br %r14

function %umulhi_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = umulhi.i32 v0, v1
  return v2
}

; block0:
;   llgfr %r2, %r2
;   llgfr %r4, %r3
;   msgr %r2, %r4
;   srlg %r2, %r2, 32
;   br %r14

function %umulhi_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = umulhi.i16 v0, v1
  return v2
}

; block0:
;   llhr %r2, %r2
;   llhr %r4, %r3
;   msr %r2, %r4
;   srlk %r2, %r2, 16
;   br %r14

function %umulhi_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = umulhi.i8 v0, v1
  return v2
}

; block0:
;   llcr %r2, %r2
;   llcr %r4, %r3
;   msr %r2, %r4
;   srlk %r2, %r2, 8
;   br %r14

function %smulhi_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = smulhi.i64 v0, v1
  return v2
}

; block0:
;   mgrk %r0, %r2, %r3
;   lgr %r2, %r0
;   br %r14

function %smulhi_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = smulhi.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r2, %r2
;   lgfr %r4, %r3
;   msgr %r2, %r4
;   srag %r2, %r2, 32
;   br %r14

function %smulhi_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = smulhi.i16 v0, v1
  return v2
}

; block0:
;   lhr %r2, %r2
;   lhr %r4, %r3
;   msr %r2, %r4
;   srak %r2, %r2, 16
;   br %r14

function %smulhi_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = smulhi.i8 v0, v1
  return v2
}

; block0:
;   lbr %r2, %r2
;   lbr %r4, %r3
;   msr %r2, %r4
;   srak %r2, %r2, 8
;   br %r14

function %sdiv_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = sdiv.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r2
;   llihf %r4, 2147483647
;   iilf %r4, 4294967295
;   xgrk %r2, %r4, %r1
;   ngrk %r4, %r2, %r3
;   cgite %r4, -1
;   dsgr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %sdiv_i64_imm(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 2
  v2 = sdiv.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r2
;   lghi %r2, 2
;   dsgr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %sdiv_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = sdiv.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r1, %r2
;   iilf %r4, 2147483647
;   xrk %r5, %r4, %r1
;   nrk %r4, %r5, %r3
;   cite %r4, -1
;   dsgfr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %sdiv_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 2
  v2 = sdiv.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r1, %r2
;   lhi %r2, 2
;   dsgfr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %sdiv_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = sdiv.i16 v0, v1
  return v2
}

; block0:
;   lghr %r1, %r2
;   lhr %r3, %r3
;   lhi %r5, 32767
;   xrk %r4, %r5, %r1
;   nrk %r5, %r4, %r3
;   cite %r5, -1
;   dsgfr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %sdiv_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 2
  v2 = sdiv.i16 v0, v1
  return v2
}

; block0:
;   lghr %r1, %r2
;   lhi %r2, 2
;   dsgfr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %sdiv_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = sdiv.i8 v0, v1
  return v2
}

; block0:
;   lgbr %r1, %r2
;   lbr %r3, %r3
;   lhi %r5, 127
;   xrk %r4, %r5, %r1
;   nrk %r5, %r4, %r3
;   cite %r5, -1
;   dsgfr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %sdiv_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 2
  v2 = sdiv.i8 v0, v1
  return v2
}

; block0:
;   lgbr %r1, %r2
;   lhi %r2, 2
;   dsgfr %r0, %r2
;   lgr %r2, %r1
;   br %r14

function %udiv_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = udiv.i64 v0, v1
  return v2
}

; block0:
;   lghi %r0, 0
;   lgr %r1, %r2
;   dlgr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i64_imm(i64) -> i64 {
block0(v0: i64):
  v1 = iconst.i64 2
  v2 = udiv.i64 v0, v1
  return v2
}

; block0:
;   lghi %r0, 0
;   lgr %r1, %r2
;   lghi %r3, 2
;   dlgr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = udiv.i32 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   lgr %r1, %r2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i32_imm(i32) -> i32 {
block0(v0: i32):
  v1 = iconst.i32 2
  v2 = udiv.i32 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   lgr %r1, %r2
;   lhi %r3, 2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = udiv.i16 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llhr %r1, %r2
;   llhr %r4, %r3
;   dlr %r0, %r4
;   lgr %r2, %r1
;   br %r14

function %udiv_i16_imm(i16) -> i16 {
block0(v0: i16):
  v1 = iconst.i16 2
  v2 = udiv.i16 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llhr %r1, %r2
;   lhi %r3, 2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %udiv_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = udiv.i8 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llcr %r1, %r2
;   llcr %r4, %r3
;   dlr %r0, %r4
;   lgr %r2, %r1
;   br %r14

function %udiv_i8_imm(i8) -> i8 {
block0(v0: i8):
  v1 = iconst.i8 2
  v2 = udiv.i8 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llcr %r1, %r2
;   lhi %r3, 2
;   dlr %r0, %r3
;   lgr %r2, %r1
;   br %r14

function %srem_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = srem.i64 v0, v1
  return v2
}

; block0:
;   lgr %r1, %r2
;   cghi %r3, -1
;   locghie %r1, 0
;   dsgr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %srem_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = srem.i32 v0, v1
  return v2
}

; block0:
;   lgfr %r1, %r2
;   dsgfr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %srem_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = srem.i16 v0, v1
  return v2
}

; block0:
;   lghr %r1, %r2
;   lhr %r3, %r3
;   dsgfr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %srem_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = srem.i8 v0, v1
  return v2
}

; block0:
;   lgbr %r1, %r2
;   lbr %r3, %r3
;   dsgfr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %urem_i64(i64, i64) -> i64 {
block0(v0: i64, v1: i64):
  v2 = urem.i64 v0, v1
  return v2
}

; block0:
;   lghi %r0, 0
;   lgr %r1, %r2
;   dlgr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %urem_i32(i32, i32) -> i32 {
block0(v0: i32, v1: i32):
  v2 = urem.i32 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   lgr %r1, %r2
;   dlr %r0, %r3
;   lgr %r2, %r0
;   br %r14

function %urem_i16(i16, i16) -> i16 {
block0(v0: i16, v1: i16):
  v2 = urem.i16 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llhr %r1, %r2
;   llhr %r4, %r3
;   dlr %r0, %r4
;   lgr %r2, %r0
;   br %r14

function %urem_i8(i8, i8) -> i8 {
block0(v0: i8, v1: i8):
  v2 = urem.i8 v0, v1
  return v2
}

; block0:
;   lhi %r0, 0
;   llcr %r1, %r2
;   llcr %r4, %r3
;   dlr %r0, %r4
;   lgr %r2, %r0
;   br %r14

